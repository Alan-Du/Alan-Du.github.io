{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping Note Book\n",
    "--- Jun-30-2020, Alan, Shaolun.du@gmail.com\n",
    "\n",
    "This is a detailed python web scraping tool for China's commodity future data (includes price{open, high, low, close}, volume, OPI and exchange inventory data) and then we combine stock data from Yahoo Finance, foreign exchange data from US st.louis federal reserve to generate an integrated trading panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Exchange website scraping\n",
    "There are 4 major commodity exchange in China, Zhengzhou exchange, Shanghai exchange, Dalian exchange and Zhongjin exchange. Most of tickers traded in Zhengzhou are agricultural commodity, Shanghai is more focused on metals, Dalian is more interested in Chemical products and Zhongjin is special for financial index products.\n",
    "\n",
    "Their corresponding websites below:\n",
    "* Shanghai exchange: http://www.shfe.com.cn/.\n",
    "* Zhengzhou exchange: http://www.czce.com.cn/.\n",
    "* Dalian exchange: http://www.dce.com.cn/.\n",
    "* Zhongjin exchange: http://www.cffex.com.cn/.\n",
    "\n",
    "In the following, I will walk you through both price scraping and inventory data scraping directly from those exchanges above. Then we will store those data into local database for further usage. Also I will talk about how to calculate price index and we can show side-by-side plot with price index and other technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Dependent library imports\n",
    "\"\"\"\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime,re\n",
    "from abc import ABC, abstractmethod\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-a Zhengzhou exchange\n",
    "### Daily exchange price data (open, high, low, close, vol, opi)\n",
    "Daily exchange price data located in Zhengzhou exchange website-->daily trading information--> pick a date to display. Please also refer to this website as an example: http://www.czce.com.cn/cn/jysj/mrhq/H770301index_1.htm\n",
    "\n",
    "![title](img/ZZ_web.jpg)\n",
    "The above screenshot is their daily market trading information, we will extract the table of market in this picture using this request format:\"http://www.czce.com.cn/cn/DFSStaticFiles/Future/{Year}/{Date}/FutureDataDaily.htm\"\n",
    "\n",
    "The way to find this url for requesting via inspection on current web and look into \"network\" tab. Whenever a new request come in, we will get a file transfered from network and you will find the corresponding file address listed above.\n",
    "\n",
    "For example a simple requests url with date \"2020-06-29\" looks like below: \"http://www.czce.com.cn/cn/DFSStaticFiles/Future/2020/20200629/FutureDataDaily.htm\"\n",
    "\n",
    "Now, we will use python request with beautiful soup module to parse this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This is date list generator for all exchanges url format\n",
    "\"\"\"\n",
    "def gen_proc_params(exc, start_date_str, end_date_str):\n",
    "    def check_date_format(date_str):\n",
    "        if re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", date_str):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    date_list = []\n",
    "    if check_date_format(start_date_str) and \\\n",
    "        check_date_format(end_date_str):\n",
    "        year_start, month_start, day_start = start_date_str.split(\"-\")\n",
    "        year_end, month_end, day_end = end_date_str.split(\"-\")\n",
    "        start_date = datetime.date(int(year_start),\n",
    "                                   int(month_start),\n",
    "                                   int(day_start))\n",
    "        end_date = datetime.date(int(year_end),\n",
    "                                 int(month_end),\n",
    "                                 int(day_end))\n",
    "        delta_days = (end_date-start_date).days\n",
    "        i = 0\n",
    "        if delta_days>=0:\n",
    "            while i <= delta_days:\n",
    "                date = start_date+datetime.timedelta(days=i)\n",
    "                if exc == \"ZZ\":\n",
    "                    date_list.append([date.strftime('%Y'),date.strftime('%Y%m%d')])\n",
    "                elif exc == \"SH\":\n",
    "                    date_list.append(date.strftime('%Y%m%d'))\n",
    "                elif exc == \"DL\":\n",
    "                    date_list.append([int(date.strftime('%Y')),int(date.strftime('%m'))-1,int(date.strftime('%d')),date])\n",
    "                elif exc == \"ZJ\":\n",
    "                    date_list.append([date.strftime('%Y%m'),date.strftime('%d')])\n",
    "                elif exc == \"SH_inv\":\n",
    "                    date_list.append([date.strftime(\"%Y\"),date.strftime('%Y%m%d'),date])\n",
    "                else:\n",
    "                    print(\"Exchange code:{} error\".format(exc))\n",
    "                    raise\n",
    "                i += 1\n",
    "            return date_list\n",
    "        else:\n",
    "            print(\"input params end date is earlier than start_date\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"Date format incorrect. Should be yyyy-mm-dd.\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also will build a prototype of exchange parser with abstract functions outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class exc_parser(ABC):\n",
    "    @abstractmethod\n",
    "    def _download(self, *args, **kwargs): \n",
    "        # Download market information from exchange\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def _get_data_df(self, *args, **kwargs): \n",
    "        # Return dataframe\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def _get_URL_TEMP(self, *args, **kwargs): \n",
    "        # Return url template\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def _read_html_format(self, *args, **kwargs):\n",
    "        # Return data frame after read html\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZZ_parser(exc_parser):\n",
    "    \"\"\" Zhengzhou exchange parser\n",
    "    \"\"\"\n",
    "    def __init__( self ):\n",
    "        self.__col_names = [\"Dates\",\"Code\",\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]\n",
    "        self.__exc_name = \"ZZ\"\n",
    "        self.__datas     = []\n",
    "    def _get_URL_TEMP(self, cur_Y):\n",
    "        # update exchange url\n",
    "        if cur_Y >= 2015:\n",
    "            URL_TEMPL = \"http://www.czce.com.cn/cn/DFSStaticFiles/Future/{}/{}/FutureDataDaily.htm\"\n",
    "        elif cur_Y < 2015:\n",
    "            URL_TEMPL = \"http://www.czce.com.cn/cn/exchange/{}/datadaily/{}.htm\"\n",
    "        else:\n",
    "            print(\"Year not found.\")\n",
    "            raise\n",
    "        return URL_TEMPL\n",
    "    def _read_html_format(self, cur_Y, page):\n",
    "        if cur_Y < 2018:\n",
    "            # Minor table format changes since 2018\n",
    "            df = pd.read_html(page,skiprows=1,attrs={\"id\":\"senfe\"})[0]\n",
    "        else:\n",
    "            df = pd.read_html(page,skiprows=0)[0]\n",
    "        return df\n",
    "    def _download(self,sdate,edate):\n",
    "        print(\"Exchange ZZ--->\")\n",
    "        # Start downloading given period\n",
    "        dates_li = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        ans = pd.DataFrame()\n",
    "        with requests.Session() as s:\n",
    "            # Open request session\n",
    "            for dates in dates_li:\n",
    "                print(dates)\n",
    "                URL_TEMPL = self._get_URL_TEMP(int(dates[0]))\n",
    "                url = URL_TEMPL.format(dates[0],dates[1])\n",
    "                try:\n",
    "                    page = s.get(url).text\n",
    "                    df = self._read_html_format(int(dates[0]),page)\n",
    "                except:\n",
    "                    continue\n",
    "                df.columns = [i for i in range(14)]\n",
    "                df[\"Dates\"] = dates[1]\n",
    "                df = df[[\"Dates\",0,2,3,4,5,10,9]]\n",
    "                df.columns = self.__col_names\n",
    "                df = df.dropna()\n",
    "                # Delete some non ASCII rows scrpped\n",
    "                df = df[df[\"Code\"].str.len()<=10]\n",
    "                ans = ans.append(df)\n",
    "        self.__datas = ans\n",
    "    def _get_data_df(self):\n",
    "        # Convert output format\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Code\"] = self.__datas[\"Code\"].astype(str)\n",
    "        self.__datas[[\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]] = self.__datas[[\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]].astype(float)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange ZZ--->\n",
      "['2020', '20200628']\n",
      "['2020', '20200629']\n",
      "['2020', '20200630']\n",
      "             Code    Open    High     Low   Close       OPI       Vol\n",
      "Dates                                                                \n",
      "2020-06-29  AP007  6170.0  6395.0  6120.0  6364.0    1529.0    1550.0\n",
      "2020-06-29  AP010  7923.0  7970.0  7814.0  7932.0  108989.0  191122.0\n",
      "2020-06-29  AP011  7700.0  7775.0  7640.0  7737.0    3492.0     866.0\n",
      "2020-06-29  AP012  7749.0  7784.0  7668.0  7761.0    4718.0     319.0\n",
      "2020-06-29  AP101  7749.0  7809.0  7682.0  7770.0   26560.0   13736.0\n",
      "...           ...     ...     ...     ...     ...       ...       ...\n",
      "2020-06-30  ZC102     0.0     0.0     0.0     0.0       1.0       0.0\n",
      "2020-06-30  ZC103   522.8   529.0   522.8   528.4     684.0     131.0\n",
      "2020-06-30  ZC104     0.0     0.0     0.0     0.0       0.0       0.0\n",
      "2020-06-30  ZC105   517.0   524.8   516.8   522.6     339.0      93.0\n",
      "2020-06-30  ZC106     0.0     0.0     0.0     0.0       0.0       0.0\n",
      "\n",
      "[350 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "ZZ = ZZ_parser()\n",
    "ZZ._download(sdate,edate)\n",
    "raw_data = ZZ._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move on to Zhengzhou exchange inventory data scraping.\n",
    "\n",
    "To parse inventory, the data table structure is a little bit complicated than marekt price data. We will use BeautifulSoup to parse it. The parser structure looks exactly like the market price parser we wrote above, but with some special characters handling(Chinese characters).\n",
    "\n",
    "We wil do the same thing as we did before, namely implement the above exc_parser to be an exchange inventory parser.\n",
    "### Weekly exchange inventory data (Total Inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZZ_inv_parser(exc_parser):\n",
    "    def __init__(self):\n",
    "        self.__contract_code = { \"白糖SR\":\"SR\", \"一号棉CF\":\"CF\",\n",
    "                                 \"菜粕RM\":\"RM\", \"菜籽油OI\":\"OI\",\n",
    "                                 \"PTA\":\"TA\",    \"甲醇MA\":\"MA\",\n",
    "                                 \"玻璃FG\":\"FG\", \"动力煤ZC\":\"ZC\" }\n",
    "        self.__exc_name = \"ZZ\"\n",
    "        self.__datas = []\n",
    "    def _download(self, sdate,edate ): \n",
    "        # Download market information from exchange\n",
    "        print(\"Exchange ZZ downloading...\")\n",
    "        date_list = gen_proc_params(self.__exc_name, sdate, edate)\n",
    "        datas = []\n",
    "        for date_str in date_list:\n",
    "            print(date_str)\n",
    "            url_temp = self._get_URL_TEMP(int(date_str[0]))\n",
    "            url = url_temp.format(date_str[0],date_str[1])\n",
    "            resp = requests.get(url)\n",
    "            if resp.status_code == 404:\n",
    "                continue\n",
    "            elif resp.status_code != 200:\n",
    "                print(\"the resp status code of date({}) is {}\".format(date_str, resp.status_code))\n",
    "            page = resp.content.decode('utf-8')\n",
    "            self._read_html_format(int(date_str[0]), page, datas, date_str[1])\n",
    "        df = pd.DataFrame(datas)\n",
    "        self.__datas = df\n",
    "    def _get_URL_TEMP(self, cur_Y):\n",
    "        # update exchange url\n",
    "        if cur_Y > 2015:\n",
    "            URL_TEMPL = \"http://www.czce.com.cn/cn/DFSStaticFiles/Future/{}/{}/FutureDataWhsheet.htm\"\n",
    "        elif cur_Y <= 2015:\n",
    "            URL_TEMPL = \"http://www.czce.com.cn/cn/exchange/{}/datawhsheet/{}.htm\"\n",
    "        else:\n",
    "            print(\"Year not found.\")\n",
    "            raise\n",
    "        return URL_TEMPL\n",
    "    def _read_html_format(self, cur_Y, page, datas, date_str):\n",
    "        # Return data frame after read html\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        tables = soup.findAll(\"table\")\n",
    "        for table in tables:\n",
    "            if cur_Y > 2017:\n",
    "                # Format to get contract code changed since 2017\n",
    "                try:\n",
    "                    contract = table.b.get_text().split(u\"单位\")[0].strip().split(u\"：\")[-1]\n",
    "                except:\n",
    "                    continue\n",
    "            elif cur_Y <= 2017 and table.b:\n",
    "                contract = table.b.get_text().split(u\"单位\")[0].strip().split(u\"：\")[-1]\n",
    "            idx = 0 # Column index for inventory\n",
    "            for tag in table.findAll(\"tr\")[1].findAll(\"td\"):\n",
    "                if u\"仓单数量\" in tag.get_text():\n",
    "                    break\n",
    "                else:\n",
    "                    idx += 1\n",
    "            if contract in self.__contract_code.keys():\n",
    "                contract = self.__contract_code[contract]\n",
    "                for row in table.findAll(\"tr\"):\n",
    "                    if row.findAll(\"td\")[0].get_text() == u\"总计\":\n",
    "                        loc_t = row.findAll(\"td\")[idx]\n",
    "                        if len(loc_t.findAll(\"td\")) == 0:\n",
    "                            invent = int(float((loc_t.get_text())))\n",
    "                        else:\n",
    "                            invent = int(float(loc_t.findAll(\"td\")[0].get_text()))\n",
    "                        datas.append({\"Product\":contract,\"Dates\":date_str,\"INV\":invent})\n",
    "                        break\n",
    "        return 0\n",
    "    def _get_data_df(self):\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Product\"] = self.__datas[\"Product\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange ZZ downloading...\n",
      "['2020', '20200628']\n",
      "['2020', '20200629']\n",
      "['2020', '20200630']\n",
      "           Product     INV\n",
      "Dates                     \n",
      "2020-06-29      SR   11251\n",
      "2020-06-29      CF   21245\n",
      "2020-06-29      RM    1870\n",
      "2020-06-29      OI     300\n",
      "2020-06-29      TA  221777\n",
      "2020-06-29      MA    5000\n",
      "2020-06-29      FG       0\n",
      "2020-06-29      ZC       0\n",
      "2020-06-30      SR   11201\n",
      "2020-06-30      CF   21069\n",
      "2020-06-30      RM    1870\n",
      "2020-06-30      OI     300\n",
      "2020-06-30      TA  222692\n",
      "2020-06-30      MA    6682\n",
      "2020-06-30      FG       0\n",
      "2020-06-30      ZC       0\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "ZZ_inv = ZZ_inv_parser()\n",
    "ZZ_inv._download(sdate,edate)\n",
    "raw_data = ZZ_inv._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-b Shanghai exchange\n",
    "I will write in short since they all have similar structure and we are using almost the same program to scrap. \n",
    "\n",
    "Start from here, we also do the market information scraping first and then exchange inventory scraping next. \n",
    "\n",
    "For Shanghai exchange, it has a very good format and this format never changed in the past which makes us super easy to scrap and use. See this link here, take 20200623 as example: http://www.shfe.com.cn/data/dailydata/20200623.dat \n",
    "![title](img/SH_web.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SH_parser(exc_parser):\n",
    "    \"\"\" Shanghai exchange parser\n",
    "    \"\"\"\n",
    "    def __init__( self ):\n",
    "        self.__col_names = [\"Dates\",\"Code\",\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]\n",
    "        self.__exc_name = \"SH\"\n",
    "        self.__datas     = []\n",
    "    def _get_URL_TEMP(self):\n",
    "        # update exchange url\n",
    "        URL_TEMPL = \"http://www.shfe.com.cn/data/dailydata/{}.dat\"\n",
    "        return URL_TEMPL\n",
    "    def _read_html_format(self,dates, jsonObj, temp_ans):\n",
    "        tradingday = dates\n",
    "        for idx, l in enumerate(jsonObj['o_cursor']):\n",
    "            if not re.match(r'\\S+\\d\\d\\d\\d', l['INSTRUMENTID']):\n",
    "                continue\n",
    "            try:\n",
    "                temp_ans.append([ tradingday, l['INSTRUMENTID'].strip(),\n",
    "                                  float(l['OPENPRICE']), float(l['HIGHESTPRICE']),\n",
    "                                  float(l['LOWESTPRICE']), float(l['CLOSEPRICE']),\n",
    "                                  float(l['OPENINTEREST']), float(l['VOLUME']) ])\n",
    "            except:\n",
    "                continue\n",
    "        return temp_ans\n",
    "    def _download(self,sdate,edate):\n",
    "        print(\"Exchange SH--->\")\n",
    "        # Start downloading given period\n",
    "        dates_li = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        temp_ans = []\n",
    "        with requests.Session() as s:\n",
    "            # Open request session\n",
    "            for dates in dates_li:\n",
    "                print(dates)\n",
    "                URL_TEMPL = self._get_URL_TEMP()\n",
    "                url = URL_TEMPL.format(dates)\n",
    "                resp = s.get(url)\n",
    "                jsonObj = json.loads(resp.content.decode('utf-8'))\n",
    "                temp_ans = self._read_html_format(dates, jsonObj, temp_ans)\n",
    "        self.__datas = pd.DataFrame(temp_ans)\n",
    "        self.__datas.columns = self.__col_names\n",
    "    def _get_data_df(self):\n",
    "        # Convert output format\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Code\"] = self.__datas[\"Code\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange SH--->\n",
      "20200628\n",
      "20200629\n",
      "20200630\n",
      "              Code     Open     High      Low    Close       OPI       Vol\n",
      "Dates                                                                     \n",
      "2020-06-29  cu2007  48040.0  48720.0  48040.0  48500.0   66864.0   48989.0\n",
      "2020-06-29  cu2008  48050.0  48590.0  48030.0  48380.0  120364.0  101302.0\n",
      "2020-06-29  cu2009  47860.0  48470.0  47860.0  48290.0   74780.0   36893.0\n",
      "2020-06-29  cu2010  47730.0  48350.0  47730.0  48150.0   50624.0   14996.0\n",
      "2020-06-29  cu2011  47750.0  48210.0  47750.0  48080.0   16217.0    3351.0\n",
      "...            ...      ...      ...      ...      ...       ...       ...\n",
      "2020-06-30  sp2012   4604.0   4604.0   4452.0   4482.0   11936.0   13166.0\n",
      "2020-06-30  sp2101   4512.0   4536.0   4506.0   4518.0    6670.0    3583.0\n",
      "2020-06-30  sp2102   4544.0   4562.0   4542.0   4552.0       8.0      50.0\n",
      "2020-06-30  sp2103   4592.0   4592.0   4592.0   4592.0       3.0       1.0\n",
      "2020-06-30  sp2105   4662.0   4674.0   4642.0   4674.0      66.0       5.0\n",
      "\n",
      "[368 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "SH = SH_parser()\n",
    "SH._download(sdate,edate)\n",
    "raw_data = SH._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly exchange inventory data (Total Inventory)\n",
    "Now let's get all Shanghai exchange inventory data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SH_inv_parser(exc_parser):\n",
    "    def __init__(self):\n",
    "        self.__contract_code = { \"铜\":\"cu\",\"铝\":\"al\",\"锌\":\"zn\",\"铅\":\"pb\",\n",
    "                                 \"镍\":\"ni\",\"锡\":\"sn\",\"天然橡胶\":\"ru\",\n",
    "                                 \"沥青仓库\":\"bu_warehouse\",\"沥青厂库\":\"bu_factory\",\n",
    "                                 \"螺纹钢\":\"rb\",\"热轧卷板\":\"hc\",\n",
    "                                 \"黄金\":\"au\",\"白银\":\"ag\",\"原油\":\"sc\",\n",
    "                                 \"线材\":\"zl\", \"中质含硫原油\":\"sc\",\n",
    "                                 \"燃料油\":\"fu\",\"纸浆\":\"sp\",\"20号胶\":\"nr\",\n",
    "                               }\n",
    "        self.__exc_name = \"SH_inv\"\n",
    "        self.__col_names = ['Dates', 'Product', 'INV']\n",
    "        self.__datas = []\n",
    "    def _get_URL_TEMP(self):\n",
    "        # update exchange url\n",
    "        URL_TEMPL = \"http://www.shfe.com.cn/data/dailydata/{}dailystock.dat\"\n",
    "        return URL_TEMPL\n",
    "    def _download(self, sdate,edate ):\n",
    "        # Download market information from exchange\n",
    "        print(\"Exchange SH inv downloading...\")\n",
    "        date_list = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        datas = []\n",
    "        for date_str in date_list:\n",
    "            print(date_str)\n",
    "            URL_TEMP = self._get_URL_TEMP()\n",
    "            url = URL_TEMP.format(date_str[1])\n",
    "            resp = requests.get(url)\n",
    "            if resp.status_code == 404:\n",
    "                continue\n",
    "            elif resp.status_code != 200:\n",
    "                print(\"the resp status code of date({}) is {}\".format(date_str[0:2], resp.status_code))\n",
    "            jsonObj = json.loads(resp.content.decode('utf-8'))\n",
    "            datas = self._read_html_format(jsonObj, date_str, datas)\n",
    "        df = pd.DataFrame(datas)\n",
    "        try:\n",
    "            df.columns = self.__col_names\n",
    "        except:\n",
    "            df = pd.DataFrame(columns = self.__col_names)\n",
    "        # Over write to english product name\n",
    "        df = df.replace({\"Product\":self.__contract_code})\n",
    "        self.__datas = df\n",
    "    def _read_html_format(self,jsonObj, date_str,datas):\n",
    "        for idx, l in enumerate(jsonObj['o_cursor']):\n",
    "            # Pay attention to gold with different format\n",
    "            if re.match(r'\\S+?\\$\\$GOLD$', l['VARNAME']):\n",
    "                datas.append([date_str[2], l['VARNAME'].split('$$')[0],float(l['WRTWGHTS'])])\n",
    "            if not re.match(r'\\S+?\\$\\$Total$', l['WHABBRNAME']):\n",
    "                continue\n",
    "            datas.append([date_str[2], l['VARNAME'].split('$$')[0],float(l['WRTWGHTS'])])\n",
    "        return datas\n",
    "    def _get_data_df(self):\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Product\"] = self.__datas[\"Product\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange SH inv downloading...\n",
      "['2020', '20200628', datetime.date(2020, 6, 28)]\n",
      "['2020', '20200629', datetime.date(2020, 6, 29)]\n",
      "['2020', '20200630', datetime.date(2020, 6, 30)]\n",
      "                 Product         INV\n",
      "Dates                               \n",
      "2020-06-29            cu     36417.0\n",
      "2020-06-29            al     90404.0\n",
      "2020-06-29            zn     37225.0\n",
      "2020-06-29            pb     16887.0\n",
      "2020-06-29            ni     28191.0\n",
      "2020-06-29            sn      2621.0\n",
      "2020-06-29            au      1890.0\n",
      "2020-06-29            ag   2098926.0\n",
      "2020-06-29            rb      4741.0\n",
      "2020-06-29            zl         0.0\n",
      "2020-06-29            hc     12837.0\n",
      "2020-06-29            sc  34670000.0\n",
      "2020-06-29            fu    536380.0\n",
      "2020-06-29  bu_warehouse     72000.0\n",
      "2020-06-29    bu_factory    264680.0\n",
      "2020-06-29            ru    229840.0\n",
      "2020-06-29            nr     51076.0\n",
      "2020-06-29            sp     92654.0\n",
      "2020-06-30            cu     36763.0\n",
      "2020-06-30            al     89827.0\n",
      "2020-06-30            zn     37099.0\n",
      "2020-06-30            pb     16887.0\n",
      "2020-06-30            ni     28191.0\n",
      "2020-06-30            sn      2786.0\n",
      "2020-06-30            au      1890.0\n",
      "2020-06-30            ag   2085941.0\n",
      "2020-06-30            rb      6811.0\n",
      "2020-06-30            zl         0.0\n",
      "2020-06-30            hc      8003.0\n",
      "2020-06-30            sc  34670000.0\n",
      "2020-06-30            fu    536380.0\n",
      "2020-06-30  bu_warehouse     72000.0\n",
      "2020-06-30    bu_factory    264680.0\n",
      "2020-06-30            ru    229390.0\n",
      "2020-06-30            nr     50370.0\n",
      "2020-06-30            sp     92654.0\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "SH_inv = SH_inv_parser()\n",
    "SH_inv._download(sdate,edate)\n",
    "raw_data = SH_inv._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-c Dalian exchange\n",
    "The next section we will finish Dalian exchange parser, it is a little complicated compared to Zhengzhou and Shanghai exchange. We will have to do post method in order to get reponse of data.\n",
    "\n",
    "The Dalian website looks like this: http://www.dce.com.cn/dalianshangpin/xqsj/tjsj26/rtj/rxq/index.html\n",
    "\n",
    "![title](img/SH_web.jpg)\n",
    "The reponse data always has the same file name as \"dayQuotesCh.html\". We have to use post method to tell the server return which date's data. To do that we define a web payload structure, the object paramaters looks a little different than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DL_parser(exc_parser):\n",
    "    \"\"\" Shanghai exchange parser\n",
    "    \"\"\"\n",
    "    def __init__( self ):\n",
    "        self.__col_names = [\"Dates\",\"Code\",\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]\n",
    "        self.__exc_name  = \"DL\"\n",
    "        self.__URL_TEMPL = \"http://www.dce.com.cn/publicweb/quotesdata/dayQuotesCh.html\"\n",
    "        self.__headers   = { 'Content-Type': 'application/x-www-form-urlencoded',\n",
    "                             'Cookie': 'JSESSIONID=34581314E8E6F047ABE7D22180DCE3A2; WMONID=-b8uBX4vHDi; Hm_lvt_a50228174de2a93aee654389576b60fb=1567732473,1568333912,1568936184,1569113640; Hm_lpvt_a50228174de2a93aee654389576b60fb=1569113660',\n",
    "                             'Referer': 'http://www.dce.com.cn/publicweb/quotesdata/dayQuotesCh.html',\n",
    "                             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "                           }\n",
    "        self.__payload  = { 'dayQuotes.variety': 'all',\n",
    "                           'dayQuotes.trade_type': '0',\n",
    "                           'year': 0,\n",
    "                           'month':0,\n",
    "                           'day':  0,\n",
    "                         }\n",
    "        self.__name_map = {\"豆一\":\"a\",\"豆二\":\"b\",\"乙二醇\":\"eg\",\"焦煤\":\"jm\",\"焦炭\":\"j\",\n",
    "                           \"铁矿石\":\"i\",\"聚氯乙烯\":\"pvc\",\"聚丙烯\":\"pp\",\"聚乙烯\":\"pe\",\"豆粕\":\"m\",\n",
    "                           \"豆油\":\"y\",\"棕榈油\":\"p\",\"鸡蛋\":\"jd\",\"玉米淀粉\":\"cs\",\"玉米\":\"c\"}\n",
    "        self.__datas     = []\n",
    "    def _get_URL_TEMP(self):\n",
    "        # update exchange url\n",
    "        return self.__URL_TEMPL\n",
    "    def _read_html_format(self,page,dates):\n",
    "        df = pd.read_html(page,skiprows=0)[0]\n",
    "        df.iloc[:,0] = df.iloc[:,0].map(self.__name_map)\n",
    "        df = df.dropna()\n",
    "        df[\"Dates\"] = str(dates[0])+\"{:02d}\".format(dates[1]+1)+\"{:02d}\".format(dates[2])\n",
    "        df[\"Code\"]  = df.iloc[:,0]+df.iloc[:,1].astype(int).astype(str)\n",
    "        df[\"Open\"]  = df.iloc[:,2]\n",
    "        df[\"High\"]  = df.iloc[:,3]\n",
    "        df[\"Low\"]   = df.iloc[:,4]\n",
    "        df[\"Close\"] = df.iloc[:,5]\n",
    "        df[\"OPI\"]   = df.iloc[:,11]\n",
    "        df[\"Vol\"]   = df.iloc[:,10]\n",
    "        df = df[[\"Dates\",\"Code\",\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]]\n",
    "        return df \n",
    "    def _download(self,sdate,edate):\n",
    "        print(\"Exchange DL--->\")\n",
    "        # Start downloading given period\n",
    "        dates_li = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        ans = pd.DataFrame()\n",
    "        with requests.Session() as s:\n",
    "            # Open request session\n",
    "            for dates in dates_li:\n",
    "                print(dates)\n",
    "                self.__payload['year'] = dates[0]\n",
    "                self.__payload['month'] = dates[1]\n",
    "                self.__payload['day'] = dates[2]\n",
    "                page = s.post( self.__URL_TEMPL, data=self.__payload, headers=self.__headers).text\n",
    "                try:\n",
    "                    df = self._read_html_format(page,dates)\n",
    "                except:\n",
    "                    continue\n",
    "                ans = ans.append(df)\n",
    "        self.__datas = ans\n",
    "    def _get_data_df(self):\n",
    "        # Convert output format\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Code\"] = self.__datas[\"Code\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange DL--->\n",
      "[2020, 5, 28, datetime.date(2020, 6, 28)]\n",
      "[2020, 5, 29, datetime.date(2020, 6, 29)]\n",
      "[2020, 5, 30, datetime.date(2020, 6, 30)]\n",
      "             Code  Open  High   Low   Close     OPI     Vol\n",
      "Dates                                                      \n",
      "2020-06-29  a2007  5418  5438  5352  5438.0     561      81\n",
      "2020-06-29  a2009  4698  4858  4670  4839.0  165912  273937\n",
      "2020-06-29  a2011  4320  4459  4317  4418.0     617     153\n",
      "2020-06-29  a2101  4326  4435  4321  4420.0   51244   37659\n",
      "2020-06-29  a2103  4447  4462  4447  4462.0      53       6\n",
      "...           ...   ...   ...   ...     ...     ...     ...\n",
      "2020-06-30  y2011  5674  5730  5674  5688.0     412      28\n",
      "2020-06-30  y2012     -     -     -  5736.0      22       0\n",
      "2020-06-30  y2101  5658  5736  5658  5704.0  189287   52462\n",
      "2020-06-30  y2103     -     -     -  5874.0       9       0\n",
      "2020-06-30  y2105  5728  5758  5712  5726.0   16604    3659\n",
      "\n",
      "[308 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "DL = DL_parser()\n",
    "DL._download(sdate,edate)\n",
    "raw_data = DL._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly exchange inventory data (Total Inventory)\n",
    "Now let's get all Dalian exchange inventory data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DL_inv_parser(exc_parser):\n",
    "    def __init__(self):\n",
    "        self.__col_names = [\"Product\",\"Location\",\"Y-D Inv\",\"INV\",\"Chg\"]\n",
    "        self.__exc_name  = \"DL\"\n",
    "        self.__URL_TEMPL = \"http://www.dce.com.cn/publicweb/quotesdata/wbillWeeklyQuotes.html\"\n",
    "        self.__headers   = { 'Content-Type': 'application/x-www-form-urlencoded',\n",
    "                             'Cookie': 'JSESSIONID=B2D36827C18F04E470A15A12B7C75AE5; WMONID=Zzot0IEoeuA; Hm_lvt_a50228174de2a93aee654389576b60fb=1569244935,1569337963,1569432080; Hm_lpvt_a50228174de2a93aee654389576b60fb=1569432127',\n",
    "                             'Referer': 'http://www.dce.com.cn/publicweb/quotesdata/wbillWeeklyQuotes.html',\n",
    "                             'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "                         }\n",
    "        self.__payload  = { 'wbillWeeklyQuotes.variety': 'all',\n",
    "                            'year': 0,\n",
    "                            'month':0,\n",
    "                            'day':  0,\n",
    "                          }\n",
    "        self.__name_map = {\"豆一\":\"a\",\"豆二\":\"b\",\"乙二醇\":\"eg\",\"焦煤\":\"jm\",\"焦炭\":\"j\",\n",
    "                           \"铁矿石\":\"i\",\"聚氯乙烯\":\"pvc\",\"聚丙烯\":\"pp\",\"聚乙烯\":\"pe\",\"豆粕\":\"m\",\n",
    "                           \"豆油\":\"y\",\"棕榈油\":\"p\",\"鸡蛋\":\"jd\",\"玉米淀粉\":\"cs\",\"玉米\":\"c\",\n",
    "                          \"苯乙烯\":\"eb\",\"纤维板\":\"fb\"}\n",
    "        self.__datas     = []\n",
    "    def _get_URL_TEMP(self):\n",
    "        # update exchange url\n",
    "        return self.__URL_TEMPL\n",
    "    def _read_html_format(self,page,dates):\n",
    "        df = pd.read_html(page,skiprows=0)[0]\n",
    "        df.columns = self.__col_names\n",
    "        df = df.fillna(\"NA\")\n",
    "        df = df[df[\"Product\"].str.contains(\"小计\")]\n",
    "        df[\"Product\"] = df[\"Product\"].str.replace(\"小计\", \"\")\n",
    "        df = df.replace({\"Product\":self.__name_map})[[\"Product\",\"INV\"]]\n",
    "        df[\"Dates\"] = dates[3]\n",
    "        df = df[[\"Dates\",\"Product\",\"INV\"]]\n",
    "        return df \n",
    "    def _download(self,sdate,edate):\n",
    "        print(\"Exchange DL Inv--->\")\n",
    "        # Start downloading given period\n",
    "        dates_li = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        ans = pd.DataFrame()\n",
    "        with requests.Session() as s:\n",
    "            # Open request session\n",
    "            for dates in dates_li:\n",
    "                print(dates)\n",
    "                self.__payload['year'] = dates[0]\n",
    "                self.__payload['month'] = dates[1]\n",
    "                self.__payload['day'] = dates[2]\n",
    "                page = s.post( self.__URL_TEMPL, data=self.__payload, headers=self.__headers).text\n",
    "                try:\n",
    "                    df = self._read_html_format(page,dates)\n",
    "                except:\n",
    "                    continue\n",
    "                ans = ans.append(df)\n",
    "        self.__datas = ans\n",
    "    def _get_data_df(self):\n",
    "        # Convert output format\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Product\"] = self.__datas[\"Product\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange DL Inv--->\n",
      "[2020, 5, 28, datetime.date(2020, 6, 28)]\n",
      "[2020, 5, 29, datetime.date(2020, 6, 29)]\n",
      "[2020, 5, 30, datetime.date(2020, 6, 30)]\n",
      "           Product    INV\n",
      "Dates                    \n",
      "2020-06-29       a      8\n",
      "2020-06-29       c  48957\n",
      "2020-06-29      cs    123\n",
      "2020-06-29      eb   1198\n",
      "2020-06-29      eg   9364\n",
      "2020-06-29      fb    201\n",
      "2020-06-29      jd     44\n",
      "2020-06-29      pe    252\n",
      "2020-06-29       m  22358\n",
      "2020-06-29       p    500\n",
      "2020-06-29      pp    163\n",
      "2020-06-29     pvc    461\n",
      "2020-06-29       y  15655\n",
      "2020-06-30       a      8\n",
      "2020-06-30       b   1600\n",
      "2020-06-30       c  46899\n",
      "2020-06-30      cs    123\n",
      "2020-06-30      eb      0\n",
      "2020-06-30      eg   9364\n",
      "2020-06-30      fb    201\n",
      "2020-06-30      jd      0\n",
      "2020-06-30      pe    431\n",
      "2020-06-30       m  22358\n",
      "2020-06-30       p    500\n",
      "2020-06-30      pp    163\n",
      "2020-06-30     pvc    461\n",
      "2020-06-30       y  15655\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "DL_Inv = DL_inv_parser()\n",
    "DL_Inv._download(sdate,edate)\n",
    "raw_data = DL_Inv._get_data_df()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-d Zhongjin exchange\n",
    "This is the last section for exchange python scraping. Zhongjin exchange is located in Shanghai and they have similar website layout. Also the responce structure is similar in JASON format.\n",
    "\n",
    "Zhongjin exchange website looks like below: http://www.cffex.com.cn/\n",
    "![title](img/ZJ_web.jpg)\n",
    "The good thing for Zhongjin is they do not have any inventory. Since they only trade financial commodity futures like G-bond futures and stock index futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZJ_parser(exc_parser):\n",
    "    \"\"\" Shanghai exchange parser\n",
    "    \"\"\"\n",
    "    def __init__( self ):\n",
    "        self.__URL_TEMPL = \"http://www.cffex.com.cn/sj/hqsj/rtj/{}/{}/index.xml\"\n",
    "        self.__headers   = [\"Dates\",\"Code\",\"Open\",\"High\",\"Low\",\"Close\",\"OPI\",\"Vol\"]\n",
    "        self.__exc_name  = \"ZJ\"\n",
    "        self.__datas     = []\n",
    "    def _get_URL_TEMP(self):\n",
    "        # update exchange url\n",
    "        return self.__URL_TEMPL\n",
    "    def _read_html_format(self,page, df):\n",
    "        etree = ET.fromstring(page)\n",
    "        for i in etree.iter(tag='dailydata'):\n",
    "            df = df.append(\n",
    "                pd.Series([ i.find('tradingday').text,i.find('instrumentid').text,\n",
    "                            i.find('openprice').text,i.find('highestprice').text,\n",
    "                            i.find('lowestprice').text,i.find('closeprice').text,\n",
    "                            i.find('openinterest').text,i.find('volume').text], index=self.__headers),\n",
    "                            ignore_index=True)\n",
    "        return df \n",
    "    def _download(self,sdate,edate):\n",
    "        print(\"Exchange ZJ--->\")\n",
    "        # Start downloading given period\n",
    "        import pandas as pd\n",
    "        import xml.etree.ElementTree as ET\n",
    "        import requests\n",
    "        df = pd.DataFrame(columns=self.__headers)\n",
    "        dates_li = gen_proc_params(self.__exc_name,sdate,edate)\n",
    "        with requests.Session() as s:\n",
    "            for dates in dates_li:\n",
    "                print(dates)\n",
    "                url = self.__URL_TEMPL.format(dates[0],dates[1])\n",
    "                page = s.get(url).text\n",
    "                try:\n",
    "                    df = self._read_html_format(page, df)\n",
    "                except:\n",
    "                    continue\n",
    "        self.__datas = df\n",
    "    def _get_data_df(self):\n",
    "        # Convert output format\n",
    "        self.__datas = self.__datas.dropna()\n",
    "        self.__datas[\"Dates\"] = pd.to_datetime(self.__datas[\"Dates\"]).dt.date\n",
    "        self.__datas = self.__datas.set_index(\"Dates\")\n",
    "        self.__datas[\"Code\"] = self.__datas[\"Code\"].astype(str)\n",
    "        return self.__datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange ZJ--->\n",
      "['202006', '28']\n",
      "['202006', '29']\n",
      "['202006', '30']\n",
      "              Code     Open     High      Low    Close    OPI    Vol\n",
      "Dates                                                               \n",
      "2020-06-29  IC2007   5729.4     5738   5668.8   5710.6  89387  70963\n",
      "2020-06-29  IC2008   5657.4   5671.8   5603.2   5641.2   2225   1245\n",
      "2020-06-29  IC2009   5600.2   5607.8     5536   5572.8  59774  13823\n",
      "2020-06-29  IC2012     5426   5435.6     5370   5407.2  34823   6163\n",
      "2020-06-29  IF2007   4100.8   4108.6   4052.2     4078  90974  73040\n",
      "...            ...      ...      ...      ...      ...    ...    ...\n",
      "2020-06-30  TF2012  101.165  101.285  101.085  101.285   1844    252\n",
      "2020-06-30  TF2103  100.645   100.66   100.55   100.66    273     24\n",
      "2020-06-30  TS2009    101.1   101.23    101.1   101.22  15857   5852\n",
      "2020-06-30  TS2012  100.985   101.04   100.93  101.035   3368    302\n",
      "2020-06-30  TS2103  100.725  100.725  100.725  100.725     33      2\n",
      "\n",
      "[496 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testing run below\n",
    "sdate = '2020-06-28'\n",
    "edate = '2020-06-30'\n",
    "ZJ = ZJ_parser()\n",
    "ZJ._download(sdate,edate)\n",
    "raw_data = ZJ._get_data_df()\n",
    "print(raw_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
